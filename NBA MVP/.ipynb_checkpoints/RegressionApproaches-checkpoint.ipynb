{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once we set our hyperparameters and features we can test on our validation set and see how our model performs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data Scraping/DataTrainSet.csv')\n",
    "test_data  = pd.read_csv('../Data Scraping/Cut_Data/data_2019_Norm.csv')\n",
    "\n",
    "\n",
    "train_data = train_data.drop(train_data[train_data.points_won <0.01].index)\n",
    "test_data = test_data.drop(test_data[test_data.pts_per_g <0.6].index)\n",
    "\n",
    "features = ['ts_pct', 'bpm', 'pts_per_g', 'trb_per_g', 'ast_per_g',\n",
    "            'stl_per_g', 'blk_per_g', 'ws'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsA = np.zeros((25,3)); \n",
    "def get_predictions_for_regression_model(model, poly_fit, train_data, test_data,  year, should_print=True):\n",
    "    test_data  = pd.read_csv('../Data Scraping/Cut_Data/data_'+str(year)+'_Norm.csv')\n",
    "    test_data = test_data.drop(test_data[test_data.pts_per_g <0.6].index)\n",
    "    \n",
    "    \n",
    "    train_x = train_data[features].to_numpy()\n",
    "    train_y = train_data['points_won'].to_numpy()\n",
    "    \n",
    "    train_y = train_y.reshape(train_y.shape[0], )\n",
    "    \n",
    "    test_x = test_data[features].to_numpy()\n",
    "    test_x = np.nan_to_num(test_x)\n",
    "    test_data2 = test_data[features2].to_numpy()\n",
    "    \n",
    "    if poly_fit is not None:\n",
    "        train_x = poly_fit.fit_transform(train_x)\n",
    "        test_x = poly_fit.fit_transform(test_x)\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    predict_y = model.predict(test_x)\n",
    "    predict_y = predict_y.reshape(predict_y.shape[0], 1)\n",
    "    \n",
    "    \n",
    "    results = np.append(test_data2, predict_y[:], 1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearList = [2018]\n",
    "#predictionArray\n",
    "for i in yearList:\n",
    "    A1=get_predictions_for_regression_model(\n",
    "        model = RandomForestRegressor(n_estimators=100, min_samples_split=2, oob_score=True),\n",
    "        poly_fit = PolynomialFeatures(degree=1, interaction_only=False),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "        \n",
    "    );\n",
    "        \n",
    "\n",
    "for i in yearList:\n",
    "    A2 = get_predictions_for_regression_model(\n",
    "        model = Ridge(alpha=1.0, solver = 'svd'),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "\n",
    "    \n",
    "for i in yearList:\n",
    "    A3 = get_predictions_for_regression_model(\n",
    "        model = GradientBoostingRegressor(  loss='ls', learning_rate=0.5, n_estimators=300),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "    \n",
    "for i in yearList:\n",
    "    A4 = get_predictions_for_regression_model(\n",
    "        model = SGDRegressor( loss='squared_epsilon_insensitive',\n",
    "            epsilon=0.0001,\n",
    "            learning_rate='adaptive',\n",
    "            eta0=0.01),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "for i in yearList:\n",
    "    A5 = get_predictions_for_regression_model(\n",
    "        model = MLPRegressor(hidden_layer_sizes=(1000,), activation='relu',solver='lbfgs'),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros(shape=(0,0))\n",
    "for i in range(0, A1.shape[0]):\n",
    "    score = np.append(score,A1[i,-1]+A2[i,-1]+A3[i,-1]+A4[i,-1]+A5[i,-1])\n",
    "\n",
    "names = np.zeros(shape=(0,0))\n",
    "for i in range(0, A1.shape[0]):\n",
    "    names = np.append(names, A2[i,0])\n",
    "    \n",
    "scores = np.zeros(shape=(A1.shape[0], 3))\n",
    "data = {\"Player Name\":names, \"Random Forest\":A1[:,-1],\"Ridge\":A2[:,-1],\"Gradient Boosting\":A3[:,-1],\"SGD\":A4[:,-1],\"MLP\":A5[:,-1],\"Actual Score\":A1[:,-2],\"score\":score}\n",
    "scoresDF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Player Name Random Forest       Ridge Gradient Boosting  \\\n",
      "5          MarShon Brooks     0.0418742   -0.292486          0.111324   \n",
      "33              John Wall      0.100786   -0.130593         -0.160445   \n",
      "4            Devin Booker      0.057325    -0.13106         0.0246029   \n",
      "29        Dennis Schröder      0.041037   -0.141339         0.0438646   \n",
      "34            T.J. Warren     0.0329744    -0.18536       -0.00032823   \n",
      "13           Tyreke Evans     0.0400385  -0.0944478          0.048681   \n",
      "25       Donovan Mitchell     0.0289852  -0.0901867          0.144555   \n",
      "2         Harrison Barnes      0.031676   -0.170454          0.130952   \n",
      "30          Klay Thompson     0.0360711   -0.117832         0.0554651   \n",
      "36           Lou Williams     0.0590502   0.0149874          0.063945   \n",
      "18           Jrue Holiday     0.0284873   0.0178136        0.00362726   \n",
      "23            CJ McCollum     0.0413176  -0.0207942         0.0702791   \n",
      "15          Blake Griffin     0.0359109  0.00678035          0.078626   \n",
      "17          Tobias Harris     0.0325971  -0.0622816         0.0368935   \n",
      "24        Khris Middleton     0.0285575  -0.0153688          0.143492   \n",
      "6            Jimmy Butler     0.0745031    0.108127         0.0695355   \n",
      "3            Bradley Beal     0.0721297   0.0262761          0.168153   \n",
      "19           Kyrie Irving      0.046422    0.136807         0.0219173   \n",
      "32           Kemba Walker     0.0394973    0.102452          0.040651   \n",
      "14            Paul George     0.0611628   0.0916597          0.222945   \n",
      "28     Kristaps Porziņģis      0.175987  -0.0924363          0.195209   \n",
      "26         Victor Oladipo     0.0917667   0.0877561          0.314411   \n",
      "27             Chris Paul     0.0493291    0.174605         0.0651345   \n",
      "10          DeMar DeRozan     0.0654821    0.153611          0.042397   \n",
      "8           Stephen Curry     0.0861009    0.196359         -0.019898   \n",
      "7        DeMarcus Cousins      0.097712   0.0632213          0.378311   \n",
      "12            Joel Embiid      0.180264    0.102415          0.403339   \n",
      "21           Nikola Jokić      0.311601    0.275217          0.149921   \n",
      "22         Damian Lillard      0.400203    0.398875           0.13392   \n",
      "35      Russell Westbrook      0.137715    0.390085          0.396524   \n",
      "0       LaMarcus Aldridge      0.304587     0.21932          0.496347   \n",
      "11           Kevin Durant      0.258764    0.361115         0.0331277   \n",
      "1   Giannis Antetokounmpo      0.483905     0.45339          0.292446   \n",
      "31     Karl-Anthony Towns      0.589526    0.423528          0.371114   \n",
      "20           LeBron James      0.629821    0.650304          0.702866   \n",
      "16           James Harden      0.766748    0.691805          0.995226   \n",
      "9           Anthony Davis      0.701499     0.64304          0.971313   \n",
      "\n",
      "           SGD         MLP Actual Score     score  \n",
      "5    -0.338463    0.117972            0 -0.359779  \n",
      "33   -0.126104 -0.00129641            0 -0.317653  \n",
      "4    -0.158754  -0.0303022            0 -0.238189  \n",
      "29   -0.174645   0.0326364            0 -0.198446  \n",
      "34   -0.210458    0.282597            0 -0.080575  \n",
      "13   -0.115822   0.0745559            0 -0.046995  \n",
      "25   -0.112647   0.0510762            0  0.021783  \n",
      "2    -0.182859    0.298577            0  0.107892  \n",
      "30   -0.133701    0.302479            0  0.142482  \n",
      "36  0.00543952   0.0200339            0  0.163456  \n",
      "18   0.0211904   0.0976038            0  0.168722  \n",
      "23  -0.0303493    0.123096            0  0.183549  \n",
      "15  -0.0109469   0.0862084            0  0.196579  \n",
      "17  -0.0683817     0.27349            0  0.212317  \n",
      "24  -0.0262245    0.092585            0  0.223041  \n",
      "6     0.109191  -0.0968833   0.00518135  0.264474  \n",
      "3    0.0184393   0.0471689            0  0.332167  \n",
      "19     0.13978 -0.00766002            0  0.337266  \n",
      "32    0.104404    0.073123            0  0.360127  \n",
      "14   0.0821348  -0.0167145            0  0.441188  \n",
      "28   -0.125996    0.310692            0  0.463455  \n",
      "26   0.0816181    -0.10732   0.00207254  0.468232  \n",
      "27    0.195557 -0.00624263            0  0.478383  \n",
      "10    0.161075   0.0901258    0.0331606  0.512691  \n",
      "8     0.201551   0.0965092   0.00518135  0.560622  \n",
      "7    0.0610956    0.106624            0  0.706964  \n",
      "12   0.0887269    0.704388   0.00414508  1.479132  \n",
      "21    0.289452    0.479658            0  1.505848  \n",
      "22    0.427623     0.14972     0.214508  1.510341  \n",
      "35    0.437586    0.191556    0.0787565  1.553466  \n",
      "0     0.230404    0.655039   0.00621762  1.905697  \n",
      "11    0.374657    0.997736    0.0683938  2.025399  \n",
      "1     0.475645    0.362402    0.0777202  2.067788  \n",
      "31    0.441231     0.91499            0  2.740390  \n",
      "20    0.708998    0.504455     0.764767  3.196444  \n",
      "16    0.762479    0.204478            1  3.420737  \n",
      "9      0.63665     1.29331      0.46114  4.245810  \n"
     ]
    }
   ],
   "source": [
    "print(scoresDF.sort_values('score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
