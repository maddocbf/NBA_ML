{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once we set our hyperparameters and features we can test on our validation set and see how our model performs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Data Scraping/DataTrainSet.csv')\n",
    "test_data  = pd.read_csv('../Data Scraping/Cut_Data/data_2019_Norm.csv')\n",
    "\n",
    "\n",
    "train_data = train_data.drop(train_data[train_data.points_won <0.01].index)\n",
    "test_data = test_data.drop(test_data[test_data.pts_per_g <0.6].index)\n",
    "\n",
    "features = ['ts_pct', 'bpm', 'pts_per_g', 'trb_per_g', 'ast_per_g',\n",
    "            'stl_per_g', 'blk_per_g', 'ws'];\n",
    "\n",
    "features2 = ['player','ts_pct', 'bpm', 'pts_per_g', 'trb_per_g', 'ast_per_g',\n",
    "            'stl_per_g', 'blk_per_g', 'ws', 'points_won'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player', 'pos_x', 'age_x', 'team_id_x', 'g_x', 'mp_x', 'fg_per_poss',\n",
       "       'fga_per_poss', 'fg_pct_x', 'fg3_per_poss', 'fg3a_per_poss',\n",
       "       'fg3_pct_x', 'fg2_per_poss', 'fg2a_per_poss', 'fg2_pct_x',\n",
       "       'ft_per_poss', 'fta_per_poss', 'ft_pct_x', 'orb_per_poss',\n",
       "       'drb_per_poss', 'trb_per_poss', 'ast_per_poss', 'stl_per_poss',\n",
       "       'blk_per_poss', 'tov_per_poss', 'pf_per_poss', 'pts_per_poss',\n",
       "       'off_rtg', 'def_rtg', 'per', 'ts_pct', 'fg3a_per_fga_pct',\n",
       "       'fta_per_fga_pct', 'orb_pct', 'drb_pct', 'trb_pct', 'ast_pct',\n",
       "       'stl_pct', 'blk_pct', 'tov_pct', 'usg_pct', 'ws-dum', 'ows', 'dws',\n",
       "       'ws', 'ws_per_48', 'bpm-dum', 'obpm', 'dbpm', 'bpm', 'vorp', 'mp_per_g',\n",
       "       'fg_per_g', 'fga_per_g', 'fg3_per_g', 'fg3a_per_g', 'fg2_per_g',\n",
       "       'fg2a_per_g', 'efg_pct', 'ft_per_g', 'fta_per_g', 'orb_per_g',\n",
       "       'drb_per_g', 'trb_per_g', 'ast_per_g', 'stl_per_g', 'blk_per_g',\n",
       "       'tov_per_g', 'pf_per_g', 'pts_per_g', 'fg_per_mp', 'fga_per_mp',\n",
       "       'fg3_per_mp', 'fg3a_per_mp', 'fg2_per_mp', 'fg2a_per_mp', 'ft_per_mp',\n",
       "       'fta_per_mp', 'orb_per_mp', 'drb_per_mp', 'trb_per_mp', 'ast_per_mp',\n",
       "       'stl_per_mp', 'blk_per_mp', 'tov_per_mp', 'pf_per_mp', 'pts_per_mp',\n",
       "       'votes_first', 'points_won'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsA = np.zeros((25,3)); \n",
    "def get_predictions_for_regression_model(model, poly_fit, train_data, test_data,  year, should_print=True):\n",
    "    test_data  = pd.read_csv('../Data Scraping/Cut_Data/data_'+str(year)+'_Norm.csv')\n",
    "    test_data = test_data.drop(test_data[test_data.pts_per_g <0.6].index)\n",
    "    \n",
    "    \n",
    "    train_x = train_data[features].to_numpy()\n",
    "    train_y = train_data['points_won'].to_numpy()\n",
    "    \n",
    "    train_y = train_y.reshape(train_y.shape[0], )\n",
    "    \n",
    "    test_x = test_data[features].to_numpy()\n",
    "    test_x = np.nan_to_num(test_x)\n",
    "    test_data2 = test_data[features2].to_numpy()\n",
    "    \n",
    "    if poly_fit is not None:\n",
    "        train_x = poly_fit.fit_transform(train_x)\n",
    "        test_x = poly_fit.fit_transform(test_x)\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    predict_y = model.predict(test_x)\n",
    "    predict_y = predict_y.reshape(predict_y.shape[0], 1)\n",
    "    \n",
    "    \n",
    "    results = np.append(test_data2, predict_y[:], 1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maddocbf/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "yearList = [2018]\n",
    "#predictionArray\n",
    "for i in yearList:\n",
    "    A1=get_predictions_for_regression_model(\n",
    "        model = RandomForestRegressor(n_estimators=100, min_samples_split=2, oob_score=True),\n",
    "        poly_fit = PolynomialFeatures(degree=1, interaction_only=False),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "        \n",
    "    );\n",
    "        \n",
    "\n",
    "for i in yearList:\n",
    "    A2 = get_predictions_for_regression_model(\n",
    "        model = Ridge(alpha=1.0, solver = 'svd'),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "\n",
    "    \n",
    "for i in yearList:\n",
    "    A3 = get_predictions_for_regression_model(\n",
    "        model = GradientBoostingRegressor(  loss='ls', learning_rate=0.5, n_estimators=300),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "    \n",
    "for i in yearList:\n",
    "    A4 = get_predictions_for_regression_model(\n",
    "        model = SGDRegressor( loss='squared_epsilon_insensitive',\n",
    "            epsilon=0.0001,\n",
    "            learning_rate='adaptive',\n",
    "            eta0=0.01),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n",
    "for i in yearList:\n",
    "    A5 = get_predictions_for_regression_model(\n",
    "        model = MLPRegressor(hidden_layer_sizes=(1000,), activation='relu',solver='lbfgs'),\n",
    "        poly_fit = PolynomialFeatures(degree=2, interaction_only=True),\n",
    "        train_data=train_data,\n",
    "        test_data=test_data, \n",
    "        year = i\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros(shape=(0,0))\n",
    "for i in range(0, A1.shape[0]):\n",
    "    score = np.append(score,A1[i,-1]+A2[i,-1]+A3[i,-1]+A4[i,-1]+A5[i,-1])\n",
    "\n",
    "names = np.zeros(shape=(0,0))\n",
    "for i in range(0, A1.shape[0]):\n",
    "    names = np.append(names, A2[i,0])\n",
    "    \n",
    "scores = np.zeros(shape=(A1.shape[0], 3))\n",
    "data = {\"Player Name\":names, \"Random Forest\":A1[:,-1],\"Ridge\":A2[:,-1],\"Gradient Boosting\":A3[:,-1],\"SGD\":A4[:,-1],\"MLP\":A5[:,-1],\"Actual Score\":A1[:,-2],\"score\":score}\n",
    "scoresDF = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Player Name Random Forest       Ridge Gradient Boosting  \\\n",
      "29        Dennis Schröder     0.0502706   -0.141339           0.04533   \n",
      "5          MarShon Brooks      0.036411   -0.292486        0.00412804   \n",
      "33              John Wall      0.129404   -0.130593         -0.159979   \n",
      "4            Devin Booker     0.0489842    -0.13106         0.0246029   \n",
      "13           Tyreke Evans     0.0445656  -0.0944478         0.0474115   \n",
      "25       Donovan Mitchell     0.0280649  -0.0901867          0.037526   \n",
      "18           Jrue Holiday     0.0377613   0.0178136        0.00409351   \n",
      "24        Khris Middleton     0.0285163  -0.0153688         0.0364625   \n",
      "34            T.J. Warren     0.0381488    -0.18536         0.0193434   \n",
      "2         Harrison Barnes     0.0313144   -0.170454          0.129883   \n",
      "36           Lou Williams     0.0492182   0.0149874         0.0636348   \n",
      "17          Tobias Harris     0.0330138  -0.0622816         0.0378527   \n",
      "30          Klay Thompson     0.0368474   -0.117832         0.0847589   \n",
      "3            Bradley Beal      0.054867   0.0262761         0.0598546   \n",
      "23            CJ McCollum     0.0343316  -0.0207942         0.0712383   \n",
      "6            Jimmy Butler      0.066549    0.108127         0.0695355   \n",
      "15          Blake Griffin     0.0284084  0.00678035          0.078626   \n",
      "27             Chris Paul     0.0684174    0.174605         0.0665372   \n",
      "32           Kemba Walker     0.0342279    0.102452         0.0393816   \n",
      "19           Kyrie Irving     0.0402881    0.136807         0.0206479   \n",
      "14            Paul George     0.0593753   0.0916597          0.115916   \n",
      "8           Stephen Curry     0.0809147    0.196359         -0.019898   \n",
      "26         Victor Oladipo     0.0915214   0.0877561          0.143338   \n",
      "10          DeMar DeRozan     0.0696213    0.153611         0.0411276   \n",
      "28     Kristaps Porziņģis      0.180274  -0.0924363          0.193093   \n",
      "7        DeMarcus Cousins      0.135323   0.0632213          0.416117   \n",
      "35      Russell Westbrook      0.178767    0.390085          0.193186   \n",
      "21           Nikola Jokić      0.256478    0.275217          0.301813   \n",
      "12            Joel Embiid      0.187991    0.102415          0.402873   \n",
      "22         Damian Lillard       0.41652    0.398875          0.132322   \n",
      "0       LaMarcus Aldridge      0.285922     0.21932          0.495505   \n",
      "11           Kevin Durant      0.309285    0.361115         0.0331277   \n",
      "1   Giannis Antetokounmpo      0.533932     0.45339          0.292446   \n",
      "31     Karl-Anthony Towns      0.573054    0.423528          0.371114   \n",
      "20           LeBron James      0.606007    0.650304          0.917752   \n",
      "16           James Harden      0.749559    0.691805           1.17339   \n",
      "9           Anthony Davis      0.759687     0.64304          0.970453   \n",
      "\n",
      "            SGD         MLP Actual Score     score  \n",
      "29    -0.166823   -0.121453            0 -0.334015  \n",
      "5      -0.28888     0.22951            0 -0.311316  \n",
      "33    -0.119332  0.00216659            0 -0.278332  \n",
      "4     -0.156779   0.0132995            0 -0.200953  \n",
      "13    -0.113994  -0.0454969            0 -0.161962  \n",
      "25    -0.107929   0.0521706            0 -0.080355  \n",
      "18 -0.000574623   -0.071681            0 -0.012587  \n",
      "24   -0.0417353   0.0390959            0  0.046971  \n",
      "34    -0.197151    0.384521            0  0.059502  \n",
      "2     -0.170638     0.25718            0  0.077285  \n",
      "36   -0.0123676  -0.0287881            0  0.086685  \n",
      "17   -0.0743909    0.194041            0  0.128235  \n",
      "30    -0.130217     0.29768            0  0.171237  \n",
      "3   -0.00536808   0.0452586            0  0.180888  \n",
      "23   -0.0443148    0.166212            0  0.206673  \n",
      "6     0.0771577   -0.109562   0.00518135  0.211807  \n",
      "15   -0.0421642    0.222858            0  0.294508  \n",
      "27     0.157366   -0.119174            0  0.347751  \n",
      "32     0.071088    0.104713            0  0.351862  \n",
      "19     0.102228   0.0565065            0  0.356478  \n",
      "14    0.0446283   0.0548047            0  0.366384  \n",
      "8      0.153573  -0.0393172   0.00518135  0.371632  \n",
      "26    0.0485577     0.06053   0.00207254  0.431703  \n",
      "10     0.113489    0.215997    0.0331606  0.593846  \n",
      "28    -0.156344     0.48913            0  0.613716  \n",
      "7   -0.00651405   0.0213333            0  0.629481  \n",
      "35     0.338078    0.300836    0.0787565  1.400953  \n",
      "21     0.199585    0.440533            0  1.473625  \n",
      "12    0.0156827     0.79375   0.00414508  1.502711  \n",
      "22     0.331867    0.410963     0.214508  1.690547  \n",
      "0      0.153607    0.695092   0.00621762  1.849445  \n",
      "11     0.258808     1.02495    0.0683938  1.987285  \n",
      "1       0.33483     0.53671    0.0777202  2.151309  \n",
      "31     0.306232    0.923739            0  2.597667  \n",
      "20     0.544576     1.03538     0.764767  3.754023  \n",
      "16       0.6114     0.83479            1  4.060949  \n",
      "9       0.42309     1.48981      0.46114  4.286085  \n"
     ]
    }
   ],
   "source": [
    "print(scoresDF.sort_values('score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
